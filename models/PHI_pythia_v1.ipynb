{"cells":[{"cell_type":"markdown","source":["# Environment"],"metadata":{"id":"xIVRvQ_l7Atz"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"vo1u9HiTXAFy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets\n","!pip install openpyxl\n","!pip install sentencepiece\n","!pip install islab-opendeid"],"metadata":{"id":"T5iC4JQJhkpO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import copy\n","import io\n","import math\n","import os\n","import time\n","import re\n","import random\n","import numpy as np\n","import pandas as pd\n","from datasets import load_dataset, Features, Value, concatenate_datasets, Dataset\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torch.optim import lr_scheduler, AdamW\n","from torch.utils.data import DataLoader\n","from torch.nn import functional as F\n","from tqdm import tqdm, trange\n","from tqdm.notebook import tqdm\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n","from transformers import get_linear_schedule_with_warmup\n","from islab.aicup import collate_batch_with_prompt_template, OpenDeidBatchSampler"],"metadata":{"id":"SIj12rVkM-ZR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Constant"],"metadata":{"id":"FUr-Sf-Z7_Nx"}},{"cell_type":"code","source":["\"\"\"Basic Setting\"\"\"\n","data_path = \"/content/drive/MyDrive/AIcup/data_hpw\"\n","\n","\"\"\"Data Setting\"\"\"\n","phi_category = ['PATIENT', 'DOCTOR', 'USERNAME', 'PROFESSION',\n","                'ROOM', 'DEPARTMENT', 'HOSPITAL', 'ORGANIZATION',\n","                'STREET', 'CITY', 'STATE', 'COUNTRY', 'ZIP', 'LOCATION-OTHER',\n","                'AGE', 'DATE', 'TIME', 'DURATION', 'SET', 'PHONE', 'FAX', 'EMAIL',\n","                'URL', 'IPADDR', 'SSN', 'MEDICALRECORD', 'HEALTHPLAN', 'ACCOUNT', 'LICENSE',\n","                'VEHICLE', 'DEVICE', 'BIOID', 'IDNUM']\n","\n","\"\"\"Model Constant Setting\"\"\"\n","BatchSize = 8\n","Epochs = 6\n","MaxLen = 256\n","LearningRate = 3e-5\n","# PretrainedModel = \"google/flan-t5-small\"\n","PretrainedModel = \"EleutherAI/pythia-70m\""],"metadata":{"id":"n3zxyCu_8CBv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Reading for Training"],"metadata":{"id":"d7kAkck-7N7K"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2qeh5TtuIASS"},"outputs":[],"source":["\"\"\"Data Reading\"\"\"\n","data_path1 = os.path.join(data_path, \"train_phase1.tsv\")\n","data_path2 = os.path.join(data_path, \"train_phase2.tsv\")\n","\n","data1 = load_dataset(\"csv\", data_files=data_path1, delimiter='\\t',\n","                       features = Features({\n","                              'fid': Value('string'), 'idx': Value('int64'),\n","                              'content': Value('string'), 'label': Value('string')}),\n","                              column_names=['fid', 'idx', 'content', 'label'], keep_default_na=False)\n","\n","data2 = load_dataset(\"csv\", data_files=data_path2, delimiter='\\t',\n","                       features = Features({\n","                              'fid': Value('string'), 'idx': Value('int64'),\n","                              'content': Value('string'), 'label': Value('string')}),\n","                              column_names=['fid', 'idx', 'content', 'label'], keep_default_na=False)\n","\n","print(\"pahse1 data:\", len(data1[\"train\"]))\n","print(\"pahse2 data:\", len(data2[\"train\"]))\n","print()\n","print(\"data sample:\", data1[\"train\"][200])\n","print(type(data1[\"train\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ny9tkyPe4A11"},"outputs":[],"source":["\"\"\"Data Concatenation\"\"\"\n","data = concatenate_datasets([data1['train'], data2['train']])\n","print(\"data length:\", len(data))\n","print(data[1025])\n","\n","# # small scale for test\n","# data = data.select(range(5000))\n","# print(\"test data length:\", len(data))"]},{"cell_type":"code","source":["# filter null data\n","def filter_phi_null_ratio(dataset, ratio):\n","    # get indices\n","    phi_null_indices = [i for i, item in enumerate(dataset) if item['label'] == 'PHI:Null']\n","    other_indices = [i for i, item in enumerate(dataset) if item['label'] != 'PHI:Null']\n","    print(f\"Total {len(dataset)}, PHI null {len(phi_null_indices)}, others {len(other_indices)} \")\n","\n","    # target null count\n","    target_phi_null_count = int(min(len(phi_null_indices), len(other_indices) * ratio))\n","    print(\"target_phi_null_count\", target_phi_null_count)\n","\n","    if len(phi_null_indices) > target_phi_null_count:\n","        phi_null_indices = random.sample(phi_null_indices, target_phi_null_count)\n","\n","    # reunion indices\n","    final_indices = phi_null_indices + other_indices\n","    random.shuffle(final_indices)\n","\n","    final_dataset = dataset.select(final_indices)\n","    return final_dataset\n","\n","filtered_data = filter_phi_null_ratio(data, PHINullRatio)\n","\n","# print filter information\n","phi_null_count_after = len([item for item in filtered_data if item['label'] == 'PHI:Null'])\n","other_count_after = len(filtered_data) - phi_null_count_after\n","phi_null_ratio = phi_null_count_after / other_count_after\n","\n","print(\"After filtering:\")\n","print(\"PHI: NULL count:\", phi_null_count_after)\n","print(\"Other labels count:\", other_count_after)\n","print(\"PHI: NULL to Other labels ratio:\", phi_null_ratio)\n","\n","data = filtered_data"],"metadata":{"id":"WY3WLt7fY3XV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"giYNlCPI47j1"},"outputs":[],"source":["train_data, test_data = data.train_test_split(test_size=0.10, seed=25).values()\n","print(\"train data size:\", len(train_data))\n","print(\"test data size:\", len(test_data))"]},{"cell_type":"markdown","source":["# Tokenizer Config\n"],"metadata":{"id":"5b29pdwk70Io"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_P9L_j54FD1"},"outputs":[],"source":["bos = '<|endoftext|>'\n","eos = '<|END|>'\n","pad = '<|pad|>'\n","sep ='\\n\\n####\\n\\n'\n","\n","special_tokens_dict = {'eos_token': eos, 'bos_token': bos, 'pad_token': pad, 'sep_token': sep}\n","\n","tokenizer = AutoTokenizer.from_pretrained(PretrainedModel, revision=\"step3000\")\n","tokenizer.padding_side = 'left'\n","num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n","print(f\"{tokenizer.pad_token}: {tokenizer.pad_token_id}\")"]},{"cell_type":"code","source":["# # test template\n","# print(train_data)\n","# data_list = list(train_data)\n","# tmp_list = data_list[:2]\n","# template = \"<|endoftext|> __CONTENT__\\n\\n####\\n\\n__LABEL__ <|END|>\"\n","# for data in tmp_list:\n","#   # print(data)\n","#   texts = template.replace(\"__LABEL__\", data['label']).replace(\"__CONTENT__\", data['content'])\n","#   print(texts)\n","#   print()"],"metadata":{"id":"JssTAORA9_Vx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"iDu0vdvRKP1g"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pMTzysvI5dkO"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","config = AutoConfig.from_pretrained(PretrainedModel,\n","                                    bos_token_id=tokenizer.bos_token_id,\n","                                    eos_token_id=tokenizer.eos_token_id,\n","                                    pad_token_id=tokenizer.pad_token_id,\n","                                    sep_token_id=tokenizer.sep_token_id,\n","                                    output_hidden_states=False)\n","\n","model = AutoModelForCausalLM.from_pretrained(PretrainedModel, revision=\"step3000\", config=config)\n","model.resize_token_embeddings(len(tokenizer))\n","model.to(device)\n","print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d0Mp5uYw5hNJ"},"outputs":[],"source":["optimizer = AdamW(model.parameters(),lr=LearningRate)"]},{"cell_type":"markdown","source":["# Train Dataloader"],"metadata":{"id":"Fs6NgYzUe5Zo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hWy3otmh5JQZ"},"outputs":[],"source":["train_data = list(train_data)\n","test_data = list(test_data)\n","\n","train_dataloader = DataLoader(train_data,\n","                              batch_sampler=OpenDeidBatchSampler(train_data, BatchSize),\n","                              collate_fn=lambda batch: collate_batch_with_prompt_template(batch, tokenizer),\n","                              pin_memory=True)\n","\n","test_dataloader = DataLoader(test_data,\n","                             batch_sampler=OpenDeidBatchSampler(test_data, 1),\n","                             collate_fn=lambda batch: collate_batch_with_prompt_template(batch, tokenizer),\n","                             pin_memory=True)\n","\n","dataloaders = {\"train\": train_dataloader, \"test\": test_dataloader}"]},{"cell_type":"code","source":["# # test train_dataloader\n","# titer = iter(train_dataloader)\n","# tks, labels, masks = next(titer)\n","# print(tks.shape)\n","# print(tks[0])\n","# print()\n","# print(masks.shape)\n","# print(masks[0])\n","# print()\n","# print(labels.shape)\n","# print(labels[0])\n","# print()"],"metadata":{"id":"XloQOki69Ln4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# titer = iter(test_dataloader)\n","# tks, labels, masks = next(titer)\n","# print(tks.shape)\n","# print(tks[0])\n","# print()\n","# print(masks.shape)\n","# print(masks[0])\n","# print()\n","# print(labels.shape)\n","# print(labels[0])\n","# print()"],"metadata":{"id":"-oZ3e-dzHTZM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"J70HZYqcKWd7"}},{"cell_type":"code","source":["\"\"\"Train Model\"\"\"\n","\n","# model path\n","name = str(int(time.time()))\n","save_path = os.path.join(\"drive/MyDrive/AIcup/model\", name)\n","model_name = save_path + f\"/best_{name}.pt\"\n","\n","if not os.path.isdir(save_path):\n","    os.mkdir(save_path)\n","\n","best_loss = float('inf')\n","train_losses = []\n","test_losses = []\n","\n","for epoch in range(Epochs):\n","    print(\"[Training] Epoch {}/{}\".format(epoch, Epochs - 1))\n","    print(\"-\" * 10)\n","\n","    running_loss_train = 0.0\n","    running_loss_test = 0.0\n","\n","    # Training phase\n","    model.train()\n","    for count, (seqs, labels, masks) in enumerate(tqdm(dataloaders[\"train\"])):\n","        seqs, labels, masks = seqs.to(device), labels.to(device), masks.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(input_ids=seqs, labels=labels, attention_mask=masks)\n","        loss = outputs.loss.mean()\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss_train += loss.item()\n","        # Print training losses\n","        if count % 1000 == 0 and count != 0:\n","            print(f\"Loss in epoch{epoch}-step{count}: {loss.item()}\")\n","            train_losses.append(loss.item())\n","\n","    # Print epoch train losses\n","    epoch_train_loss = running_loss_train / len(dataloaders[\"train\"])\n","    print(f\"[Training] Train Loss: {epoch_train_loss:.4f}\")\n","\n","    # Testing phase\n","    model.eval()\n","    with torch.no_grad():\n","        for seqs, labels, masks in tqdm(dataloaders[\"test\"]):\n","            seqs, labels, masks = seqs.to(device), labels.to(device), masks.to(device)\n","            outputs = model(input_ids=seqs, labels=labels, attention_mask=masks)\n","            loss = outputs.loss.mean()\n","            running_loss_test += loss.item()\n","\n","    # print epoch test loss\n","    epoch_test_loss = running_loss_test / len(dataloaders[\"test\"])\n","    print(f\"[Training] Test Loss: {epoch_test_loss:.4f}\")\n","\n","    # save the best model\n","    test_losses.append(epoch_test_loss)\n","    if epoch_test_loss < best_loss:\n","        best_loss = epoch_test_loss\n","        best_model_wts = copy.deepcopy(model.state_dict())\n","        torch.save(model.state_dict(), model_name)\n","        print(f\"[INFO] Updated best model on dev checkpoint: {model_name}\")\n"],"metadata":{"id":"mlph_1KqLUo5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Val Dataloader"],"metadata":{"id":"mqWxP2mYrjVn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"m1G0sToC6vVS"},"outputs":[],"source":["val_path = os.path.join(data_path, \"valid_phase1.tsv\")\n","data_val = load_dataset(\"csv\", data_files=val_path, delimiter='\\t',\n","                          features = Features({\n","                              'fid': Value('string'), 'idx': Value('int64'),\n","                              'content': Value('string'), 'label': Value('string')}),\n","                              column_names=['fid', 'idx', 'content', 'label'])\n","data_val= list(data_val['train'])\n","print(\"pahse1 validation:\", len(data_val))\n","print(\"validation sample:\", data_val[1025])"]},{"cell_type":"markdown","source":["# Generation"],"metadata":{"id":"Cmw6bDqrc-qg"}},{"cell_type":"code","source":["name = \"1699888370\"\n","model_name = f\"drive/MyDrive/AIcup/model/{name}/best_{name}.pt\"\n","answer_path = f\"drive/MyDrive/AIcup/model/{name}/answer.txt\"\n","\n","model.load_state_dict(torch.load(model_name))\n","model = model.to(device)"],"metadata":{"id":"xyzCI8Xrc8M0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentence = \"Episode No:  88Y206206L\"\n","phi_value = \"88Y206206L\"\n","matches = [(match.start(), match.end()) for match in re.finditer(phi_value, sentence)]\n","print(matches)"],"metadata":{"id":"cKeYK4dduJli"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jMOuuV0jJcEc"},"outputs":[],"source":["def get_anno_format(sentence , infos , boundary):\n","    anno_list = []\n","    lines = infos.split(\"\\n\")\n","    normalize_keys = ['DATE' , \"TIME\" , \"DURATION\" , \"SET\"]\n","    phi_dict = {}\n","    for line in lines:\n","        parts = line.split(\":\")\n","        if parts[0] not in phi_category or parts[1] == '':\n","            continue\n","        if len(parts) == 2:\n","            phi_dict[parts[0]] = parts[1].strip()\n","    for phi_key, phi_value in phi_dict.items():\n","        normalize_time = None\n","        if phi_key in normalize_keys:\n","            if '=>' in phi_value:\n","                temp_phi_values = phi_value.split('=>')\n","                phi_value = temp_phi_values[0]\n","                normalize_time = temp_phi_values[-1]\n","            else:\n","                normalize_time = phi_value\n","        try:\n","            matches = [(match.start(), match.end()) for match in re.finditer(phi_value, sentence)]\n","        except:\n","            continue\n","        for start, end in matches:\n","            if start == end:\n","                continue\n","            item_dict = {\n","                        'phi' : phi_key,\n","                        'st_idx' : start + int(boundary),\n","                        'ed_idx' : end + int(boundary),\n","                        'entity' : phi_value,\n","            }\n","            if normalize_time is not None:\n","                item_dict['normalize_time'] = normalize_time\n","            anno_list.append(item_dict)\n","    return anno_list\n","\n","def aicup_predict(model, tokenizer, input, template = \"<|endoftext|> __CONTENT__\\n\\n####\\n\\n\"):\n","    seeds = [template.replace(\"__CONTENT__\", data['content']) for data in input]\n","    sep = tokenizer.sep_token\n","    eos = tokenizer.eos_token\n","    pad = tokenizer.pad_token\n","    pad_idx = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n","    \"\"\"Generate text from a trained model.\"\"\"\n","    model.eval()\n","    device = model.device\n","    texts = tokenizer(seeds, return_tensors = 'pt', padding=True).to(device)\n","    outputs = []\n","    #return\n","    with torch.cuda.amp.autocast():\n","        output_tokens = model.generate(**texts, max_new_tokens=400, pad_token_id = pad_idx,\n","                                        eos_token_id=tokenizer.convert_tokens_to_ids(eos))\n","        preds = tokenizer.batch_decode(output_tokens)\n","        for idx , pred in enumerate(preds):\n","          if \"NULL\" in pred:\n","            continue\n","          phi_infos = pred[pred.index(sep)+len(sep):].replace(pad, \"\").replace(eos, \"\").strip()\n","          annotations = get_anno_format(input[idx]['content'] , phi_infos , input[idx]['idx'])\n","          for annotation in annotations:\n","            if 'normalize_time' in annotation:\n","              outputs.append(f'{input[idx][\"fid\"]}\\t{annotation[\"phi\"]}\\t{annotation[\"st_idx\"]}\\t{annotation[\"ed_idx\"]}\\t{annotation[\"entity\"]}\\t{annotation[\"normalize_time\"]}')\n","            else:\n","              outputs.append(f'{input[idx][\"fid\"]}\\t{annotation[\"phi\"]}\\t{annotation[\"st_idx\"]}\\t{annotation[\"ed_idx\"]}\\t{annotation[\"entity\"]}')\n","    return outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":375805,"status":"ok","timestamp":1699947438901,"user":{"displayName":"paveen Huang","userId":"09738948655551288120"},"user_tz":-480},"id":"RAtxuyFO8_kH","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["33b99d6d23234835aeb841bb25dcc2ef","52ca3376c6874de5b8be5d29317a4b66","e161caaa4b5d468b845ea40c78161592","ad2f42674e6442a4ae86de8dfe5f6c80","f3af3cfe6d834e8588d66f2d011ecd1f","f52f06b32f3f4466be17a8452250b2d0","70cce7fe066b462a9d1b00d9687a51e5","f4f54291245c47f183956e1cc1749cd5","10637f7d889f4c44a4c2801ddd20bc11","2ac8ccc250c746ef885f707eb810eb14","4b7d34cbcdbb4be4a6254153f4462200"]},"outputId":"1b0e25b2-0159-4b9c-f658-0d9e0f955984"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/805 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33b99d6d23234835aeb841bb25dcc2ef"}},"metadata":{}}],"source":["ValBatchSize = 32\n","with open(answer_path,'w',encoding='utf8') as f:\n","    for i in tqdm(range(0, len(data_val), ValBatchSize)):\n","        with torch.no_grad():\n","            seeds = data_val[i:i+ValBatchSize]\n","            outputs = aicup_predict(model, tokenizer, input=seeds)\n","            for o in outputs:\n","                f.write(o)\n","                f.write('\\n')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["xIVRvQ_l7Atz","FUr-Sf-Z7_Nx","d7kAkck-7N7K","5b29pdwk70Io"],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"},"widgets":{"application/vnd.jupyter.widget-state+json":{"33b99d6d23234835aeb841bb25dcc2ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_52ca3376c6874de5b8be5d29317a4b66","IPY_MODEL_e161caaa4b5d468b845ea40c78161592","IPY_MODEL_ad2f42674e6442a4ae86de8dfe5f6c80"],"layout":"IPY_MODEL_f3af3cfe6d834e8588d66f2d011ecd1f"}},"52ca3376c6874de5b8be5d29317a4b66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f52f06b32f3f4466be17a8452250b2d0","placeholder":"​","style":"IPY_MODEL_70cce7fe066b462a9d1b00d9687a51e5","value":"100%"}},"e161caaa4b5d468b845ea40c78161592":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4f54291245c47f183956e1cc1749cd5","max":805,"min":0,"orientation":"horizontal","style":"IPY_MODEL_10637f7d889f4c44a4c2801ddd20bc11","value":805}},"ad2f42674e6442a4ae86de8dfe5f6c80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ac8ccc250c746ef885f707eb810eb14","placeholder":"​","style":"IPY_MODEL_4b7d34cbcdbb4be4a6254153f4462200","value":" 805/805 [06:15&lt;00:00,  4.36it/s]"}},"f3af3cfe6d834e8588d66f2d011ecd1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f52f06b32f3f4466be17a8452250b2d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70cce7fe066b462a9d1b00d9687a51e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4f54291245c47f183956e1cc1749cd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10637f7d889f4c44a4c2801ddd20bc11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ac8ccc250c746ef885f707eb810eb14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b7d34cbcdbb4be4a6254153f4462200":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}